{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CifYJoNnBxKt"
      },
      "outputs": [],
      "source": [
        "from minbpe import RegexTokenizer\n",
        "\n",
        "tokenizer = RegexTokenizer()\n",
        "tokenizer_path = \"../output/tokenizer/darija_tokenizer.model\"\n",
        "tokenizer.load(model_file=tokenizer_path)\n",
        "\n",
        "\n",
        "def get_vocab_size(tokenizer: RegexTokenizer) -> int:\n",
        "    vocab = tokenizer.vocab\n",
        "    special_tokens = tokenizer.special_tokens\n",
        "\n",
        "    return len(vocab) + len(special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjnbL6csCk2y",
        "outputId": "2e4fa17b-a144-4901-d639-394cd5b17d41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: b'\\x00',\n",
              " 1: b'\\x01',\n",
              " 2: b'\\x02',\n",
              " 3: b'\\x03',\n",
              " 4: b'\\x04',\n",
              " 5: b'\\x05',\n",
              " 6: b'\\x06',\n",
              " 7: b'\\x07',\n",
              " 8: b'\\x08',\n",
              " 9: b'\\t',\n",
              " 10: b'\\n',\n",
              " 11: b'\\x0b',\n",
              " 12: b'\\x0c',\n",
              " 13: b'\\r',\n",
              " 14: b'\\x0e',\n",
              " 15: b'\\x0f',\n",
              " 16: b'\\x10',\n",
              " 17: b'\\x11',\n",
              " 18: b'\\x12',\n",
              " 19: b'\\x13',\n",
              " 20: b'\\x14',\n",
              " 21: b'\\x15',\n",
              " 22: b'\\x16',\n",
              " 23: b'\\x17',\n",
              " 24: b'\\x18',\n",
              " 25: b'\\x19',\n",
              " 26: b'\\x1a',\n",
              " 27: b'\\x1b',\n",
              " 28: b'\\x1c',\n",
              " 29: b'\\x1d',\n",
              " 30: b'\\x1e',\n",
              " 31: b'\\x1f',\n",
              " 32: b' ',\n",
              " 33: b'!',\n",
              " 34: b'\"',\n",
              " 35: b'#',\n",
              " 36: b'$',\n",
              " 37: b'%',\n",
              " 38: b'&',\n",
              " 39: b\"'\",\n",
              " 40: b'(',\n",
              " 41: b')',\n",
              " 42: b'*',\n",
              " 43: b'+',\n",
              " 44: b',',\n",
              " 45: b'-',\n",
              " 46: b'.',\n",
              " 47: b'/',\n",
              " 48: b'0',\n",
              " 49: b'1',\n",
              " 50: b'2',\n",
              " 51: b'3',\n",
              " 52: b'4',\n",
              " 53: b'5',\n",
              " 54: b'6',\n",
              " 55: b'7',\n",
              " 56: b'8',\n",
              " 57: b'9',\n",
              " 58: b':',\n",
              " 59: b';',\n",
              " 60: b'<',\n",
              " 61: b'=',\n",
              " 62: b'>',\n",
              " 63: b'?',\n",
              " 64: b'@',\n",
              " 65: b'A',\n",
              " 66: b'B',\n",
              " 67: b'C',\n",
              " 68: b'D',\n",
              " 69: b'E',\n",
              " 70: b'F',\n",
              " 71: b'G',\n",
              " 72: b'H',\n",
              " 73: b'I',\n",
              " 74: b'J',\n",
              " 75: b'K',\n",
              " 76: b'L',\n",
              " 77: b'M',\n",
              " 78: b'N',\n",
              " 79: b'O',\n",
              " 80: b'P',\n",
              " 81: b'Q',\n",
              " 82: b'R',\n",
              " 83: b'S',\n",
              " 84: b'T',\n",
              " 85: b'U',\n",
              " 86: b'V',\n",
              " 87: b'W',\n",
              " 88: b'X',\n",
              " 89: b'Y',\n",
              " 90: b'Z',\n",
              " 91: b'[',\n",
              " 92: b'\\\\',\n",
              " 93: b']',\n",
              " 94: b'^',\n",
              " 95: b'_',\n",
              " 96: b'`',\n",
              " 97: b'a',\n",
              " 98: b'b',\n",
              " 99: b'c',\n",
              " 100: b'd',\n",
              " 101: b'e',\n",
              " 102: b'f',\n",
              " 103: b'g',\n",
              " 104: b'h',\n",
              " 105: b'i',\n",
              " 106: b'j',\n",
              " 107: b'k',\n",
              " 108: b'l',\n",
              " 109: b'm',\n",
              " 110: b'n',\n",
              " 111: b'o',\n",
              " 112: b'p',\n",
              " 113: b'q',\n",
              " 114: b'r',\n",
              " 115: b's',\n",
              " 116: b't',\n",
              " 117: b'u',\n",
              " 118: b'v',\n",
              " 119: b'w',\n",
              " 120: b'x',\n",
              " 121: b'y',\n",
              " 122: b'z',\n",
              " 123: b'{',\n",
              " 124: b'|',\n",
              " 125: b'}',\n",
              " 126: b'~',\n",
              " 127: b'\\x7f',\n",
              " 128: b'\\x80',\n",
              " 129: b'\\x81',\n",
              " 130: b'\\x82',\n",
              " 131: b'\\x83',\n",
              " 132: b'\\x84',\n",
              " 133: b'\\x85',\n",
              " 134: b'\\x86',\n",
              " 135: b'\\x87',\n",
              " 136: b'\\x88',\n",
              " 137: b'\\x89',\n",
              " 138: b'\\x8a',\n",
              " 139: b'\\x8b',\n",
              " 140: b'\\x8c',\n",
              " 141: b'\\x8d',\n",
              " 142: b'\\x8e',\n",
              " 143: b'\\x8f',\n",
              " 144: b'\\x90',\n",
              " 145: b'\\x91',\n",
              " 146: b'\\x92',\n",
              " 147: b'\\x93',\n",
              " 148: b'\\x94',\n",
              " 149: b'\\x95',\n",
              " 150: b'\\x96',\n",
              " 151: b'\\x97',\n",
              " 152: b'\\x98',\n",
              " 153: b'\\x99',\n",
              " 154: b'\\x9a',\n",
              " 155: b'\\x9b',\n",
              " 156: b'\\x9c',\n",
              " 157: b'\\x9d',\n",
              " 158: b'\\x9e',\n",
              " 159: b'\\x9f',\n",
              " 160: b'\\xa0',\n",
              " 161: b'\\xa1',\n",
              " 162: b'\\xa2',\n",
              " 163: b'\\xa3',\n",
              " 164: b'\\xa4',\n",
              " 165: b'\\xa5',\n",
              " 166: b'\\xa6',\n",
              " 167: b'\\xa7',\n",
              " 168: b'\\xa8',\n",
              " 169: b'\\xa9',\n",
              " 170: b'\\xaa',\n",
              " 171: b'\\xab',\n",
              " 172: b'\\xac',\n",
              " 173: b'\\xad',\n",
              " 174: b'\\xae',\n",
              " 175: b'\\xaf',\n",
              " 176: b'\\xb0',\n",
              " 177: b'\\xb1',\n",
              " 178: b'\\xb2',\n",
              " 179: b'\\xb3',\n",
              " 180: b'\\xb4',\n",
              " 181: b'\\xb5',\n",
              " 182: b'\\xb6',\n",
              " 183: b'\\xb7',\n",
              " 184: b'\\xb8',\n",
              " 185: b'\\xb9',\n",
              " 186: b'\\xba',\n",
              " 187: b'\\xbb',\n",
              " 188: b'\\xbc',\n",
              " 189: b'\\xbd',\n",
              " 190: b'\\xbe',\n",
              " 191: b'\\xbf',\n",
              " 192: b'\\xc0',\n",
              " 193: b'\\xc1',\n",
              " 194: b'\\xc2',\n",
              " 195: b'\\xc3',\n",
              " 196: b'\\xc4',\n",
              " 197: b'\\xc5',\n",
              " 198: b'\\xc6',\n",
              " 199: b'\\xc7',\n",
              " 200: b'\\xc8',\n",
              " 201: b'\\xc9',\n",
              " 202: b'\\xca',\n",
              " 203: b'\\xcb',\n",
              " 204: b'\\xcc',\n",
              " 205: b'\\xcd',\n",
              " 206: b'\\xce',\n",
              " 207: b'\\xcf',\n",
              " 208: b'\\xd0',\n",
              " 209: b'\\xd1',\n",
              " 210: b'\\xd2',\n",
              " 211: b'\\xd3',\n",
              " 212: b'\\xd4',\n",
              " 213: b'\\xd5',\n",
              " 214: b'\\xd6',\n",
              " 215: b'\\xd7',\n",
              " 216: b'\\xd8',\n",
              " 217: b'\\xd9',\n",
              " 218: b'\\xda',\n",
              " 219: b'\\xdb',\n",
              " 220: b'\\xdc',\n",
              " 221: b'\\xdd',\n",
              " 222: b'\\xde',\n",
              " 223: b'\\xdf',\n",
              " 224: b'\\xe0',\n",
              " 225: b'\\xe1',\n",
              " 226: b'\\xe2',\n",
              " 227: b'\\xe3',\n",
              " 228: b'\\xe4',\n",
              " 229: b'\\xe5',\n",
              " 230: b'\\xe6',\n",
              " 231: b'\\xe7',\n",
              " 232: b'\\xe8',\n",
              " 233: b'\\xe9',\n",
              " 234: b'\\xea',\n",
              " 235: b'\\xeb',\n",
              " 236: b'\\xec',\n",
              " 237: b'\\xed',\n",
              " 238: b'\\xee',\n",
              " 239: b'\\xef',\n",
              " 240: b'\\xf0',\n",
              " 241: b'\\xf1',\n",
              " 242: b'\\xf2',\n",
              " 243: b'\\xf3',\n",
              " 244: b'\\xf4',\n",
              " 245: b'\\xf5',\n",
              " 246: b'\\xf6',\n",
              " 247: b'\\xf7',\n",
              " 248: b'\\xf8',\n",
              " 249: b'\\xf9',\n",
              " 250: b'\\xfa',\n",
              " 251: b'\\xfb',\n",
              " 252: b'\\xfc',\n",
              " 253: b'\\xfd',\n",
              " 254: b'\\xfe',\n",
              " 255: b'\\xff',\n",
              " 256: b'de',\n",
              " 257: b' e',\n",
              " 258: b' de',\n",
              " 259: b' l',\n",
              " 260: b' p',\n",
              " 261: b'os',\n",
              " 262: b' a',\n",
              " 263: b'ue',\n",
              " 264: b' c',\n",
              " 265: b'en',\n",
              " 266: b'ar',\n",
              " 267: b' s',\n",
              " 268: b'er',\n",
              " 269: b'es',\n",
              " 270: b'as',\n",
              " 271: b'ci',\n",
              " 272: b'on',\n",
              " 273: b'or',\n",
              " 274: b' m',\n",
              " 275: b'st',\n",
              " 276: b' q',\n",
              " 277: b' la',\n",
              " 278: b'an',\n",
              " 279: b' que',\n",
              " 280: b' t',\n",
              " 281: b'\\xc3\\xb3',\n",
              " 282: b're',\n",
              " 283: b'ad',\n",
              " 284: b'un',\n",
              " 285: b' en',\n",
              " 286: b'in',\n",
              " 287: b'ee',\n",
              " 288: b'\\xc3\\xb3n',\n",
              " 289: b'.\\n',\n",
              " 290: b'al',\n",
              " 291: b' el',\n",
              " 292: b' y',\n",
              " 293: b' n',\n",
              " 294: b'ro',\n",
              " 295: b'ent',\n",
              " 296: b' h',\n",
              " 297: b'am',\n",
              " 298: b'\\xc3\\xad',\n",
              " 299: b'ti',\n",
              " 300: b'do',\n",
              " 301: b' un',\n",
              " 302: b'om',\n",
              " 303: b' con',\n",
              " 304: b' E',\n",
              " 305: b'di',\n",
              " 306: b'aci',\n",
              " 307: b' est',\n",
              " 308: b' se',\n",
              " 309: b' es',\n",
              " 310: b'\\xc3\\xa1',\n",
              " 311: b' los',\n",
              " 312: b' v',\n",
              " 313: b'ra',\n",
              " 314: b' P',\n",
              " 315: b' S',\n",
              " 316: b'te',\n",
              " 317: b' f',\n",
              " 318: b'res',\n",
              " 319: b'eeee',\n",
              " 320: b' in',\n",
              " 321: b'to',\n",
              " 322: b' C',\n",
              " 323: b' re',\n",
              " 324: b'em',\n",
              " 325: b'aj',\n",
              " 326: b'is',\n",
              " 327: b' par',\n",
              " 328: b'ic',\n",
              " 329: b' no',\n",
              " 330: b'ec',\n",
              " 331: b' las',\n",
              " 332: b'aci\\xc3\\xb3n',\n",
              " 333: b' ha',\n",
              " 334: b' o',\n",
              " 335: b'ado',\n",
              " 336: b'bi',\n",
              " 337: b'ol',\n",
              " 338: b' com',\n",
              " 339: b'im',\n",
              " 340: b'ente',\n",
              " 341: b'\\xc3\\xa9',\n",
              " 342: b'id',\n",
              " 343: b' por',\n",
              " 344: b' me',\n",
              " 345: b' del',\n",
              " 346: b'\\xc3\\xb1',\n",
              " 347: b' al',\n",
              " 348: b'i\\xc3\\xb3n',\n",
              " 349: b'ta',\n",
              " 350: b' pro',\n",
              " 351: b' g',\n",
              " 352: b' di',\n",
              " 353: b' A',\n",
              " 354: b' una',\n",
              " 355: b' su',\n",
              " 356: b'bl',\n",
              " 357: b'pe',\n",
              " 358: b' lo',\n",
              " 359: b' si',\n",
              " 360: b' para',\n",
              " 361: b'ones',\n",
              " 362: b'tu',\n",
              " 363: b'go',\n",
              " 364: b'uest',\n",
              " 365: b'da',\n",
              " 366: b'ajaj',\n",
              " 367: b' mi',\n",
              " 368: b'ui',\n",
              " 369: b'lo',\n",
              " 370: b' L',\n",
              " 371: b'ero',\n",
              " 372: b'eeeeeeee',\n",
              " 373: b'\\xc3\\xada',\n",
              " 374: b'uro',\n",
              " 375: b'ter',\n",
              " 376: b' ac',\n",
              " 377: b'ri',\n",
              " 378: b'ch',\n",
              " 379: b'ci\\xc3\\xb3n',\n",
              " 380: b' d',\n",
              " 381: b' M',\n",
              " 382: b'ari',\n",
              " 383: b' b',\n",
              " 384: b' N',\n",
              " 385: b'se',\n",
              " 386: b'ento',\n",
              " 387: b'orm',\n",
              " 388: b'tiv',\n",
              " 389: b'ide',\n",
              " 390: b'bre',\n",
              " 391: b'ur',\n",
              " 392: b'idad',\n",
              " 393: b'ul',\n",
              " 394: b'oy',\n",
              " 395: b'\\xc3\\xa1s',\n",
              " 396: b' x',\n",
              " 397: b'le',\n",
              " 398: b' to',\n",
              " 399: b'ca',\n",
              " 400: b' Com',\n",
              " 401: b' xD',\n",
              " 402: b'cia',\n",
              " 403: b'ist',\n",
              " 404: b'ados',\n",
              " 405: b'ien',\n",
              " 406: b' Y',\n",
              " 407: b' ex',\n",
              " 408: b' so',\n",
              " 409: b'ab',\n",
              " 410: b'\\xc3\\xba',\n",
              " 411: b' Est',\n",
              " 412: b' D',\n",
              " 413: b' T',\n",
              " 414: b'ales',\n",
              " 415: b' res',\n",
              " 416: b' Se',\n",
              " 417: b'tr',\n",
              " 418: b' U',\n",
              " 419: b'ce',\n",
              " 420: b' des',\n",
              " 421: b'ando',\n",
              " 422: b'que',\n",
              " 423: b'ada',\n",
              " 424: b' esta',\n",
              " 425: b'urope',\n",
              " 426: b'tos',\n",
              " 427: b'amos',\n",
              " 428: b' cu',\n",
              " 429: b' deb',\n",
              " 430: b' ten',\n",
              " 431: b'la',\n",
              " 432: b'li',\n",
              " 433: b' pr',\n",
              " 434: b' como',\n",
              " 435: b' este',\n",
              " 436: b'amente',\n",
              " 437: b' Comis',\n",
              " 438: b'mo',\n",
              " 439: b'ambi',\n",
              " 440: b' pa',\n",
              " 441: b' ap',\n",
              " 442: b' mu',\n",
              " 443: b' m\\xc3\\xa1s',\n",
              " 444: b'emos',\n",
              " 445: b' per',\n",
              " 446: b'co',\n",
              " 447: b'ir',\n",
              " 448: b' pue',\n",
              " 449: b'us',\n",
              " 450: b' ser',\n",
              " 451: b' No',\n",
              " 452: b' po',\n",
              " 453: b'tar',\n",
              " 454: b'ten',\n",
              " 455: b' j',\n",
              " 456: b'por',\n",
              " 457: b' Un',\n",
              " 458: b'\\xc3\\xa9n',\n",
              " 459: b'iden',\n",
              " 460: b' im',\n",
              " 461: b'uen',\n",
              " 462: b' sobre',\n",
              " 463: b'ran',\n",
              " 464: b'pa',\n",
              " 465: b' te',\n",
              " 466: b'lam',\n",
              " 467: b'ante',\n",
              " 468: b'form',\n",
              " 469: b'vi',\n",
              " 470: b' an',\n",
              " 471: b'mi',\n",
              " 472: b' Si',\n",
              " 473: b'uer',\n",
              " 474: b'eeeeeeeeeeeeeeee',\n",
              " 475: b'ora',\n",
              " 476: b' Comisi\\xc3\\xb3n',\n",
              " 477: b'tes',\n",
              " 478: b' le',\n",
              " 479: b' pre',\n",
              " 480: b' tra',\n",
              " 481: b' Q',\n",
              " 482: b' Con',\n",
              " 483: b' as',\n",
              " 484: b' Por',\n",
              " 485: b'um',\n",
              " 486: b' O',\n",
              " 487: b' En',\n",
              " 488: b'puest',\n",
              " 489: b'residen',\n",
              " 490: b'dos',\n",
              " 491: b' ma',\n",
              " 492: b' Es',\n",
              " 493: b'po',\n",
              " 494: b'per',\n",
              " 495: b'ble',\n",
              " 496: b'gun',\n",
              " 497: b'das',\n",
              " 498: b'des',\n",
              " 499: b' La',\n",
              " 500: b'ambi\\xc3\\xa9n',\n",
              " 501: b'ia',\n",
              " 502: b'cer',\n",
              " 503: b'der',\n",
              " 504: b'iz',\n",
              " 505: b'ica',\n",
              " 506: b'aciones',\n",
              " 507: b' cont',\n",
              " 508: b'\\xc3\\xa1n',\n",
              " 509: b'dad',\n",
              " 510: b' Presiden',\n",
              " 511: b' Europe',\n",
              " 512: b'it',\n",
              " 513: b'ust',\n",
              " 514: b'\\xc3\\xb1or',\n",
              " 515: b'ig',\n",
              " 516: b' El',\n",
              " 517: b'ru',\n",
              " 518: b' em',\n",
              " 519: b'\\xc3\\xadti',\n",
              " 520: b'ores',\n",
              " 521: b'gr',\n",
              " 522: b'pon',\n",
              " 523: b'jo',\n",
              " 524: b' B',\n",
              " 525: b' Par',\n",
              " 526: b' ya',\n",
              " 527: b' cons',\n",
              " 528: b' tambi\\xc3\\xa9n',\n",
              " 529: b' pol',\n",
              " 530: b' ver',\n",
              " 531: b'mos',\n",
              " 532: b'ici',\n",
              " 533: b' H',\n",
              " 534: b' inform',\n",
              " 535: b'br',\n",
              " 536: b'ier',\n",
              " 537: b'\\xc3\\xads',\n",
              " 538: b' man',\n",
              " 539: b' qui',\n",
              " 540: b'\\xc3\\xban',\n",
              " 541: b'con',\n",
              " 542: b' cre',\n",
              " 543: b'gar',\n",
              " 544: b' medi',\n",
              " 545: b'ida',\n",
              " 546: b' sin',\n",
              " 547: b'ga',\n",
              " 548: b' hay',\n",
              " 549: b' inter',\n",
              " 550: b'lar',\n",
              " 551: b'lamento',\n",
              " 552: b' pol\\xc3\\xadti',\n",
              " 553: b'00',\n",
              " 554: b'port',\n",
              " 555: b'cu',\n",
              " 556: b' Uni\\xc3\\xb3n',\n",
              " 557: b' comp',\n",
              " 558: b' pe',\n",
              " 559: b' \\xc2',\n",
              " 560: b'eces',\n",
              " 561: b' R',\n",
              " 562: b' tien',\n",
              " 563: b'mente',\n",
              " 564: b' pres',\n",
              " 565: b' pos',\n",
              " 566: b' pero',\n",
              " 567: b' G',\n",
              " 568: b' Me',\n",
              " 569: b'ac',\n",
              " 570: b'ario',\n",
              " 571: b'io',\n",
              " 572: b' mo',\n",
              " 573: b'ces',\n",
              " 574: b' co',\n",
              " 575: b' pa\\xc3\\xads',\n",
              " 576: b'ech',\n",
              " 577: b' dis',\n",
              " 578: b'den',\n",
              " 579: b' sol',\n",
              " 580: b'iones',\n",
              " 581: b' deci',\n",
              " 582: b' Se\\xc3\\xb1or',\n",
              " 583: b' nuest',\n",
              " 584: b' tan',\n",
              " 585: b' Presidente',\n",
              " 586: b'fic',\n",
              " 587: b'ras',\n",
              " 588: b'ajajajaj',\n",
              " 589: b' nos',\n",
              " 590: b'du',\n",
              " 591: b' V',\n",
              " 592: b' ent',\n",
              " 593: b'aa',\n",
              " 594: b' mis',\n",
              " 595: b'ver',\n",
              " 596: b'cial',\n",
              " 597: b' ob',\n",
              " 598: b'ido',\n",
              " 599: b' ve',\n",
              " 600: b'tas',\n",
              " 601: b'cho',\n",
              " 602: b'tiva',\n",
              " 603: b'pec',\n",
              " 604: b' ca',\n",
              " 605: b' han',\n",
              " 606: b'encia',\n",
              " 607: b' pas',\n",
              " 608: b'tor',\n",
              " 609: b'me',\n",
              " 610: b' seg',\n",
              " 611: b' fin',\n",
              " 612: b' Parlamento',\n",
              " 613: b'el',\n",
              " 614: b'ciones',\n",
              " 615: b' r',\n",
              " 616: b' Europea',\n",
              " 617: b'vo',\n",
              " 618: b' son',\n",
              " 619: b'ens',\n",
              " 620: b'pres',\n",
              " 621: b' I',\n",
              " 622: b'cion',\n",
              " 623: b'hora',\n",
              " 624: b'ajj',\n",
              " 625: b'qui',\n",
              " 626: b'fer',\n",
              " 627: b' hacer',\n",
              " 628: b'adas',\n",
              " 629: b' cas',\n",
              " 630: b'rol',\n",
              " 631: b'sejo',\n",
              " 632: b' ti',\n",
              " 633: b' Estados',\n",
              " 634: b' sus',\n",
              " 635: b' Consejo',\n",
              " 636: b'era',\n",
              " 637: b' neces',\n",
              " 638: b' posi',\n",
              " 639: b'acion',\n",
              " 640: b' am',\n",
              " 641: b'baj',\n",
              " 642: b' J',\n",
              " 643: b' lu',\n",
              " 644: b' import',\n",
              " 645: b'ber',\n",
              " 646: b' ni',\n",
              " 647: b'eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee',\n",
              " 648: b'dr',\n",
              " 649: b'rec',\n",
              " 650: b'endo',\n",
              " 651: b' yo',\n",
              " 652: b' eso',\n",
              " 653: b'tado',\n",
              " 654: b' a\\xc3\\xb1',\n",
              " 655: b' (',\n",
              " 656: b'tro',\n",
              " 657: b' todo',\n",
              " 658: b' Pero',\n",
              " 659: b' Que',\n",
              " 660: b' miem',\n",
              " 661: b' propuest',\n",
              " 662: b'zar',\n",
              " 663: b' pa\\xc3\\xadses',\n",
              " 664: b'ico',\n",
              " 665: b'ven',\n",
              " 666: b' :',\n",
              " 667: b' pon',\n",
              " 668: b'bil',\n",
              " 669: b'u\\xc3\\xa9',\n",
              " 670: b' or',\n",
              " 671: b' -',\n",
              " 672: b'cl',\n",
              " 673: b' trabaj',\n",
              " 674: b' nue',\n",
              " 675: b' europe',\n",
              " 676: b'tic',\n",
              " 677: b'anos',\n",
              " 678: b'je',\n",
              " 679: b'almente',\n",
              " 680: b'ord',\n",
              " 681: b' est\\xc3\\xa1',\n",
              " 682: b' informe',\n",
              " 683: b' pl',\n",
              " 684: b'cip',\n",
              " 685: b' form',\n",
              " 686: b' lle',\n",
              " 687: b'lic',\n",
              " 688: b' muy',\n",
              " 689: b'za',\n",
              " 690: b'aria',\n",
              " 691: b' ar',\n",
              " 692: b'no',\n",
              " 693: b'ajjajajajaj',\n",
              " 694: b' entre',\n",
              " 695: b' De',\n",
              " 696: b' F',\n",
              " 697: b' vi',\n",
              " 698: b' todos',\n",
              " 699: b' ci',\n",
              " 700: b'bros',\n",
              " 701: b' pol\\xc3\\xadtica',\n",
              " 702: b' sal',\n",
              " 703: b' Sr',\n",
              " 704: b' bi',\n",
              " 705: b' pers',\n",
              " 706: b'entos',\n",
              " 707: b'\\xc3\\xadas',\n",
              " 708: b' prim',\n",
              " 709: b' reg',\n",
              " 710: b'entes',\n",
              " 711: b' As',\n",
              " 712: b' miembros',\n",
              " 713: b'ema',\n",
              " 714: b'eg',\n",
              " 715: b'tivo',\n",
              " 716: b'itu',\n",
              " 717: b'min',\n",
              " 718: b'tros',\n",
              " 719: b'unto',\n",
              " 720: b'ana',\n",
              " 721: b' Euro',\n",
              " 722: b' rec',\n",
              " 723: b' mej',\n",
              " 724: b' car',\n",
              " 725: b' cos',\n",
              " 726: b' tiene',\n",
              " 727: b'tra',\n",
              " 728: b'chos',\n",
              " 729: b' ter',\n",
              " 730: b' ra',\n",
              " 731: b' cuando',\n",
              " 732: b' fun',\n",
              " 733: b'ma',\n",
              " 734: b'aliz',\n",
              " 735: b'fec',\n",
              " 736: b'bar',\n",
              " 737: b' dere',\n",
              " 738: b'200',\n",
              " 739: b'echo',\n",
              " 740: b' tu',\n",
              " 741: b' tran',\n",
              " 742: b' porque',\n",
              " 743: b' ese',\n",
              " 744: b' li',\n",
              " 745: b' voy',\n",
              " 746: b' Europa',\n",
              " 747: b' mar',\n",
              " 748: b'il',\n",
              " 749: b' cuest',\n",
              " 750: b' tanto',\n",
              " 751: b' parte',\n",
              " 752: b'stitu',\n",
              " 753: b'uerdo',\n",
              " 754: b'uir',\n",
              " 755: b' esto',\n",
              " 756: b' puede',\n",
              " 757: b' ahora',\n",
              " 758: b'gan',\n",
              " 759: b' contra',\n",
              " 760: b'duc',\n",
              " 761: b'par',\n",
              " 762: b'emp',\n",
              " 763: b' X',\n",
              " 764: b'fici',\n",
              " 765: b'bilidad',\n",
              " 766: b'qu',\n",
              " 767: b' comun',\n",
              " 768: b'ami',\n",
              " 769: b' men',\n",
              " 770: b'arrol',\n",
              " 771: b' sab',\n",
              " 772: b' ab',\n",
              " 773: b'uci\\xc3\\xb3n',\n",
              " 774: b' \\xc2\\xbf',\n",
              " 775: b' may',\n",
              " 776: b'idades',\n",
              " 777: b' bien',\n",
              " 778: b' lugar',\n",
              " 779: b' person',\n",
              " 780: b' prin',\n",
              " 781: b'va',\n",
              " 782: b' tengo',\n",
              " 783: b' trans',\n",
              " 784: b' gran',\n",
              " 785: b'tir',\n",
              " 786: b' ej',\n",
              " 787: b' estoy',\n",
              " 788: b' cor',\n",
              " 789: b' algun',\n",
              " 790: b'los',\n",
              " 791: b' ag',\n",
              " 792: b'arios',\n",
              " 793: b' deba',\n",
              " 794: b'aba',\n",
              " 795: b' hecho',\n",
              " 796: b'cas',\n",
              " 797: b'car',\n",
              " 798: b' desarrol',\n",
              " 799: b' pu',\n",
              " 800: b'raci',\n",
              " 801: b'cias',\n",
              " 802: b' Ya',\n",
              " 803: b' mejor',\n",
              " 804: b'tivos',\n",
              " 805: b'rib',\n",
              " 806: b' mun',\n",
              " 807: b' vo',\n",
              " 808: b' ref',\n",
              " 809: b'cha',\n",
              " 810: b' Lo',\n",
              " 811: b' decir',\n",
              " 812: b'tura',\n",
              " 813: b'teri',\n",
              " 814: b'pli',\n",
              " 815: b'cio',\n",
              " 816: b'av',\n",
              " 817: b' esa',\n",
              " 818: b' Yo',\n",
              " 819: b' mer',\n",
              " 820: b' vez',\n",
              " 821: b' sig',\n",
              " 822: b' w',\n",
              " 823: b'ut',\n",
              " 824: b' leg',\n",
              " 825: b'miento',\n",
              " 826: b'mien',\n",
              " 827: b'tal',\n",
              " 828: b'pos',\n",
              " 829: b'sa',\n",
              " 830: b'las',\n",
              " 831: b' debe',\n",
              " 832: b'ros',\n",
              " 833: b've',\n",
              " 834: b' obje',\n",
              " 835: b' deber',\n",
              " 836: b' acuerdo',\n",
              " 837: b' princip',\n",
              " 838: b'ba',\n",
              " 839: b' col',\n",
              " 840: b'uego',\n",
              " 841: b'emas',\n",
              " 842: b'?\\n',\n",
              " 843: b' direc',\n",
              " 844: b' propuesta',\n",
              " 845: b' enmien',\n",
              " 846: b' probl',\n",
              " 847: b' ay',\n",
              " 848: b' va',\n",
              " 849: b' mismo',\n",
              " 850: b' pes',\n",
              " 851: b'bles',\n",
              " 852: b'pecto',\n",
              " 853: b' incl',\n",
              " 854: b'can',\n",
              " 855: b'if',\n",
              " 856: b' XD',\n",
              " 857: b' actu',\n",
              " 858: b' buen',\n",
              " 859: b' .',\n",
              " 860: b' creo',\n",
              " 861: b'zo',\n",
              " 862: b' solo',\n",
              " 863: b' cuen',\n",
              " 864: b'les',\n",
              " 865: b'ep',\n",
              " 866: b' importante',\n",
              " 867: b' segur',\n",
              " 868: b' In',\n",
              " 869: b'ja',\n",
              " 870: b'antes',\n",
              " 871: b' econ',\n",
              " 872: b' disc',\n",
              " 873: b'ular',\n",
              " 874: b' dem',\n",
              " 875: b' \\xc3\\xba',\n",
              " 876: b' do',\n",
              " 877: b' Europeo',\n",
              " 878: b'\\xc3\\xb1o',\n",
              " 879: b'ie',\n",
              " 880: b'empo',\n",
              " 881: b'\\xc3\\xa1m',\n",
              " 882: b'emente',\n",
              " 883: b' rel',\n",
              " 884: b'\\xc3\\xb3m',\n",
              " 885: b'ece',\n",
              " 886: b' hace',\n",
              " 887: b' mayor',\n",
              " 888: b' tiempo',\n",
              " 889: b' op',\n",
              " 890: b' Ha',\n",
              " 891: b'ista',\n",
              " 892: b'alidad',\n",
              " 893: b'ano',\n",
              " 894: b'udad',\n",
              " 895: b' toda',\n",
              " 896: b' \\xc3\\xa9',\n",
              " 897: b' as\\xc3\\xad',\n",
              " 898: b'bier',\n",
              " 899: b' bas',\n",
              " 900: b'cado',\n",
              " 901: b' clar',\n",
              " 902: b' embar',\n",
              " 903: b' conside',\n",
              " 904: b' dos',\n",
              " 905: b' respon',\n",
              " 906: b'ios',\n",
              " 907: b'uda',\n",
              " 908: b'reo',\n",
              " 909: b'OO',\n",
              " 910: b' apro',\n",
              " 911: b'adores',\n",
              " 912: b'uso',\n",
              " 913: b'eres',\n",
              " 914: b'nos',\n",
              " 915: b' ch',\n",
              " 916: b'ito',\n",
              " 917: b'lti',\n",
              " 918: b'esti',\n",
              " 919: b'eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee',\n",
              " 920: b'entar',\n",
              " 921: b'ren',\n",
              " 922: b' sec',\n",
              " 923: b'untos',\n",
              " 924: b' apoy',\n",
              " 925: b' cual',\n",
              " 926: b' ade',\n",
              " 927: b' hemos',\n",
              " 928: b' espe',\n",
              " 929: b' cier',\n",
              " 930: b' gen',\n",
              " 931: b'ceso',\n",
              " 932: b' fu',\n",
              " 933: b' ne',\n",
              " 934: b' quiero',\n",
              " 935: b' ju',\n",
              " 936: b'cos',\n",
              " 937: b'ion',\n",
              " 938: b' sino',\n",
              " 939: b' desde',\n",
              " 940: b' cuesti\\xc3\\xb3n',\n",
              " 941: b' anim',\n",
              " 942: b' resul',\n",
              " 943: b' parti',\n",
              " 944: b' exist',\n",
              " 945: b' pregun',\n",
              " 946: b'asta',\n",
              " 947: b'oder',\n",
              " 948: b' ciudad',\n",
              " 949: b' embargo',\n",
              " 950: b' trabajo',\n",
              " 951: b'tamente',\n",
              " 952: b' prop',\n",
              " 953: b' situ',\n",
              " 954: b' desarrollo',\n",
              " 955: b'ino',\n",
              " 956: b' \\xc3\\xbalti',\n",
              " 957: b'uar',\n",
              " 958: b'aaaa',\n",
              " 959: b' hum',\n",
              " 960: b'cios',\n",
              " 961: b'\\xc3\\xb3lo',\n",
              " 962: b' ad',\n",
              " 963: b' forma',\n",
              " 964: b' mundo',\n",
              " 965: b'ual',\n",
              " 966: b'\\xc3\\xa9s',\n",
              " 967: b'ismo',\n",
              " 968: b' qu\\xc3\\xa9',\n",
              " 969: b'ye',\n",
              " 970: b'idos',\n",
              " 971: b' debate',\n",
              " 972: b'rupo',\n",
              " 973: b' cuenta',\n",
              " 974: b' ampli',\n",
              " 975: b'gen',\n",
              " 976: b' est\\xc3\\xa1n',\n",
              " 977: b'\\xc3\\xbabl',\n",
              " 978: b'aran',\n",
              " 979: b' estas',\n",
              " 980: b' fav',\n",
              " 981: b'ancia',\n",
              " 982: b' a\\xc3\\xb1os',\n",
              " 983: b' cap',\n",
              " 984: b' mom',\n",
              " 985: b' seguridad',\n",
              " 986: b' def',\n",
              " 987: b'anci',\n",
              " 988: b' da',\n",
              " 989: b'cci\\xc3\\xb3n',\n",
              " 990: b'pl',\n",
              " 991: b'mm',\n",
              " 992: b'tur',\n",
              " 993: b'dop',\n",
              " 994: b'arse',\n",
              " 995: b'ale',\n",
              " 996: b'\\xc3\\xadan',\n",
              " 997: b'ombre',\n",
              " 998: b' Los',\n",
              " 999: b' cab',\n",
              " ...}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQlfiiw-Cocb"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUw5QzzxCrNS",
        "outputId": "47b947af-27ee-4abc-8fce-3260950171e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x704da81b7790>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(3647)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB0-gZkLCs3S",
        "outputId": "d5c467b5-04ee-4605-add9-b9f2551e381f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36.23425 M parameters\n"
          ]
        }
      ],
      "source": [
        "from transformer.model import GPTLanguageModel\n",
        "\n",
        "block_size = 1024\n",
        "n_embd = 512\n",
        "n_head = 16\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "batch_size = 2\n",
        "vocab_size = get_vocab_size(tokenizer)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = GPTLanguageModel(\n",
        "    vocab_size=vocab_size,\n",
        "    block_size=block_size,\n",
        "    n_embd=n_embd,\n",
        "    n_head=n_head,\n",
        "    n_layer=n_layer,\n",
        "    dropout=dropout,\n",
        "    device=device\n",
        ").to(device)\n",
        "\n",
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMMpc93zC8XB"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lJK2Z_7C7ib",
        "outputId": "ff3e1af3-c1b5-4155-f730-7479f7cf1430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (452560,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data_path = \"../output/encoded_data/encoded_atlaset.npy\"\n",
        "data = np.load(data_path, mmap_mode='r')\n",
        "print('Data shape:', data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k32YO0QHDHAr",
        "outputId": "f20dd606-d55a-4e96-ebf1-245cf9045f85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "407304"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_index = int(0.9*len(data))\n",
        "split_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkhB6LoNDO5G"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3JWcS0DTDJtc"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def get_batch(split: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    if split == 'train':\n",
        "        start_index = 0\n",
        "        end_index = split_index\n",
        "    else:\n",
        "        start_index = split_index\n",
        "        end_index = len(data)\n",
        "\n",
        "    index = torch.randint(start_index, end_index - block_size, (batch_size,))\n",
        "    x_batch, y_batch = [], []\n",
        "    for i in index:\n",
        "        x_batch.append(data[i:i+block_size])\n",
        "        y_batch.append(data[i+1:i+block_size+1])\n",
        "\n",
        "    x_batch = np.array(x_batch)\n",
        "    y_batch = np.array(y_batch)\n",
        "\n",
        "    x_batch = torch.tensor(x_batch, dtype=torch.long).to(device)\n",
        "    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n",
        "\n",
        "    return x_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x8nEUq8BDSKc"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss() -> Dict:\n",
        "    output = {}\n",
        "    eval_iters = 1000\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            x, y = get_batch(split)\n",
        "            _, loss = model(x, y)\n",
        "            losses[k] = loss.item()\n",
        "        output[split] = losses.mean()\n",
        "    model.train()\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SHggvNLnDTln"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(\n",
        "    model: GPTLanguageModel,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epoch: int,\n",
        "    loss: float,\n",
        "    file_path: str = \"checkpoint.pth\"\n",
        ") -> None:\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "    }\n",
        "    torch.save(checkpoint, file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMA_WyDDDflx"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YLVYqR17ER6j"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "eZhjb9yoDU3v",
        "outputId": "0dab38f6-ea25-4fc9-93c7-6acf0063d330"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 102/203140 [01:00<302:58:04,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 100: train loss 8.1642, val loss 8.0478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 202/203140 [02:01<310:01:31,  5.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 200: train loss 8.2747, val loss 8.2019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 302/203140 [03:01<305:19:29,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 300: train loss 8.3134, val loss 8.3036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 402/203140 [04:01<307:40:32,  5.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 400: train loss 8.3617, val loss 8.3449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 502/203140 [05:01<302:12:59,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 500: train loss 8.6022, val loss 8.6243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 602/203140 [06:02<310:38:22,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 600: train loss 8.8375, val loss 8.8735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 702/203140 [07:01<302:23:00,  5.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 700: train loss 8.9539, val loss 9.0021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 802/203140 [08:03<312:43:09,  5.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 800: train loss 8.9598, val loss 9.0059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 902/203140 [09:03<302:59:56,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 900: train loss 9.0689, val loss 9.1397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 1002/203140 [10:04<309:24:47,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1000: train loss 8.9933, val loss 9.0592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1102/203140 [11:04<305:06:10,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1100: train loss 9.1875, val loss 9.2370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1202/203140 [12:05<310:43:21,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1200: train loss 9.0865, val loss 9.1789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1302/203140 [13:05<305:34:14,  5.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1300: train loss 9.3265, val loss 9.4174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1402/203140 [14:07<310:00:29,  5.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1400: train loss 9.2758, val loss 9.3903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1502/203140 [15:07<304:01:34,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1500: train loss 9.5148, val loss 9.6440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1602/203140 [16:08<311:09:30,  5.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1600: train loss 9.2679, val loss 9.4000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1702/203140 [17:09<304:35:25,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1700: train loss 9.2713, val loss 9.4114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1802/203140 [18:10<312:05:01,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1800: train loss 9.4408, val loss 9.5694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 1902/203140 [19:11<306:17:45,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1900: train loss 9.4948, val loss 9.6227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 2002/203140 [20:13<311:37:37,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2000: train loss 9.4324, val loss 9.5791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 2102/203140 [21:13<304:03:26,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2100: train loss 9.3754, val loss 9.4738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 2202/203140 [22:14<307:13:30,  5.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2200: train loss 9.3578, val loss 9.4583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 2302/203140 [23:14<300:54:23,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2300: train loss 9.4496, val loss 9.5850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 2402/203140 [24:15<306:20:22,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2400: train loss 9.4520, val loss 9.6214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|          | 2502/203140 [25:14<300:24:09,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2500: train loss 9.6021, val loss 9.7465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|▏         | 2602/203140 [26:16<309:18:15,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2600: train loss 9.5259, val loss 9.6571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|▏         | 2702/203140 [27:16<302:01:17,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2700: train loss 9.4832, val loss 9.6204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|▏         | 2802/203140 [28:17<306:27:04,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2800: train loss 9.2626, val loss 9.3479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|▏         | 2902/203140 [29:16<299:32:29,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2900: train loss 9.2486, val loss 9.3764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   1%|▏         | 3002/203140 [30:17<305:58:30,  5.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3000: train loss 9.3117, val loss 9.4395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3102/203140 [31:17<300:59:47,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3100: train loss 9.4480, val loss 9.5791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3202/203140 [32:18<305:48:06,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3200: train loss 9.4012, val loss 9.5208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3302/203140 [33:19<303:56:51,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3300: train loss 9.5752, val loss 9.7119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3402/203140 [34:21<309:55:02,  5.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3400: train loss 9.5315, val loss 9.6322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3502/203140 [35:21<303:38:02,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3500: train loss 9.4863, val loss 9.6533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3602/203140 [36:23<307:28:17,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3600: train loss 9.4641, val loss 9.6045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3702/203140 [37:22<297:10:59,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3700: train loss 9.5442, val loss 9.6788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3802/203140 [38:22<300:01:56,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3800: train loss 9.5929, val loss 9.7158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 3902/203140 [39:22<298:28:37,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 3900: train loss 9.6791, val loss 9.8489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4002/203140 [40:23<307:10:32,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4000: train loss 9.6696, val loss 9.8460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4102/203140 [41:23<297:52:59,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4100: train loss 9.7675, val loss 9.9644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4202/203140 [42:24<303:40:02,  5.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4200: train loss 9.6319, val loss 9.8426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4302/203140 [43:24<298:12:53,  5.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4300: train loss 9.8513, val loss 10.0162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4402/203140 [44:25<304:35:45,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4400: train loss 9.5201, val loss 9.6675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4502/203140 [45:25<299:42:20,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4500: train loss 9.5783, val loss 9.7481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4602/203140 [46:26<305:52:37,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4600: train loss 9.5329, val loss 9.7621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4702/203140 [47:27<300:52:58,  5.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4700: train loss 9.9137, val loss 10.0936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4802/203140 [48:28<302:39:46,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4800: train loss 9.9177, val loss 10.0867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 4902/203140 [49:27<293:49:21,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 4900: train loss 9.5598, val loss 9.7043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   2%|▏         | 5002/203140 [50:27<301:41:21,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5000: train loss 9.5991, val loss 9.7413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5102/203140 [51:28<298:48:55,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5100: train loss 9.7858, val loss 9.9048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5202/203140 [52:29<306:47:05,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5200: train loss 9.5918, val loss 9.7221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5302/203140 [53:30<300:38:06,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5300: train loss 9.6457, val loss 9.8152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5402/203140 [54:31<303:32:27,  5.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5400: train loss 9.6700, val loss 9.8611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5502/203140 [55:31<296:10:44,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5500: train loss 10.0844, val loss 10.2201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5602/203140 [56:32<302:19:59,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5600: train loss 9.9370, val loss 10.1180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5702/203140 [57:32<296:16:57,  5.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5700: train loss 9.7228, val loss 9.8717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5802/203140 [58:33<304:47:18,  5.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5800: train loss 9.8796, val loss 10.0483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 5902/203140 [59:34<299:44:06,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 5900: train loss 9.9597, val loss 10.1115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6002/203140 [1:00:35<304:49:09,  5.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6000: train loss 10.3420, val loss 10.5131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6102/203140 [1:01:35<294:45:46,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6100: train loss 10.3926, val loss 10.6416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6202/203140 [1:02:35<297:37:09,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6200: train loss 9.9303, val loss 10.1660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6302/203140 [1:03:34<292:20:59,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6300: train loss 9.8126, val loss 9.9935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6402/203140 [1:04:35<300:14:28,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6400: train loss 10.0829, val loss 10.2889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6502/203140 [1:05:35<294:08:12,  5.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6500: train loss 10.0576, val loss 10.2592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6602/203140 [1:06:36<300:00:49,  5.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6600: train loss 9.8541, val loss 10.0206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6702/203140 [1:07:35<293:59:16,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6700: train loss 9.9817, val loss 10.1939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6802/203140 [1:08:35<295:45:11,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6800: train loss 9.9809, val loss 10.2194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 6902/203140 [1:09:34<288:53:48,  5.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 6900: train loss 10.2759, val loss 10.4787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 7002/203140 [1:10:34<295:03:48,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7000: train loss 9.9618, val loss 10.1560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   3%|▎         | 7102/203140 [1:11:33<292:43:06,  5.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7100: train loss 10.0106, val loss 10.2141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▎         | 7202/203140 [1:12:34<297:38:22,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7200: train loss 9.9183, val loss 10.1370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▎         | 7302/203140 [1:13:34<294:27:41,  5.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7300: train loss 9.8940, val loss 10.0548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▎         | 7402/203140 [1:14:34<297:28:16,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7400: train loss 9.7770, val loss 10.0119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▎         | 7502/203140 [1:15:34<292:46:37,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7500: train loss 9.7657, val loss 9.9837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▎         | 7602/203140 [1:16:35<298:08:24,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7600: train loss 9.8961, val loss 10.1272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 7702/203140 [1:17:34<290:33:53,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7700: train loss 10.0644, val loss 10.3130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 7802/203140 [1:18:34<294:24:29,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7800: train loss 9.8893, val loss 10.1089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 7902/203140 [1:19:35<294:52:03,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 7900: train loss 10.0938, val loss 10.3364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8002/203140 [1:20:36<299:11:55,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8000: train loss 10.0627, val loss 10.2338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8102/203140 [1:21:35<290:42:00,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8100: train loss 10.0769, val loss 10.2621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8202/203140 [1:22:36<296:50:17,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8200: train loss 10.0032, val loss 10.1956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8302/203140 [1:23:35<287:37:31,  5.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8300: train loss 10.0560, val loss 10.2789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8402/203140 [1:24:36<298:49:10,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8400: train loss 10.2825, val loss 10.4803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8502/203140 [1:25:36<294:06:24,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8500: train loss 10.3269, val loss 10.5404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8602/203140 [1:26:36<295:52:33,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8600: train loss 10.1087, val loss 10.3670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8702/203140 [1:27:37<294:14:48,  5.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8700: train loss 9.9858, val loss 10.2373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8802/203140 [1:28:38<296:14:14,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8800: train loss 9.9429, val loss 10.1885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 8902/203140 [1:29:37<289:53:06,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8900: train loss 9.9956, val loss 10.1908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 9002/203140 [1:30:38<294:44:19,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9000: train loss 9.8712, val loss 10.1198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 9102/203140 [1:31:38<292:46:25,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9100: train loss 10.0080, val loss 10.2373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9202/203140 [1:32:39<298:28:10,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9200: train loss 10.2032, val loss 10.4202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9302/203140 [1:33:39<288:30:27,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9300: train loss 10.0354, val loss 10.2487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9402/203140 [1:34:40<298:03:08,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9400: train loss 10.1273, val loss 10.3574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9502/203140 [1:35:40<291:31:06,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9500: train loss 10.1177, val loss 10.3680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9602/203140 [1:36:41<293:52:51,  5.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9600: train loss 10.2143, val loss 10.4822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9702/203140 [1:37:40<288:29:41,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9700: train loss 10.0830, val loss 10.3069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9802/203140 [1:38:41<295:03:42,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9800: train loss 10.1975, val loss 10.4203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9902/203140 [1:39:40<287:06:02,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 9900: train loss 10.3003, val loss 10.5304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 9998/203140 [1:40:00<4:56:20, 10.86it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10000: train loss 10.3464, val loss 10.5366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▍         | 10102/203140 [1:41:41<289:20:17,  5.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10100: train loss 10.4772, val loss 10.6945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10202/203140 [1:42:42<295:08:55,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10200: train loss 10.5985, val loss 10.8148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10302/203140 [1:43:41<286:41:43,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10300: train loss 10.6079, val loss 10.8460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10402/203140 [1:44:40<282:00:59,  5.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10400: train loss 10.4204, val loss 10.6612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10502/203140 [1:45:39<287:34:24,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10500: train loss 10.4452, val loss 10.6701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10602/203140 [1:46:41<296:15:15,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10600: train loss 10.4717, val loss 10.6843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10702/203140 [1:47:41<290:27:38,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10700: train loss 10.6044, val loss 10.8234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10802/203140 [1:48:42<296:12:37,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10800: train loss 10.6937, val loss 10.9382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10902/203140 [1:49:42<286:24:03,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 10900: train loss 10.6509, val loss 10.8827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   5%|▌         | 10999/203140 [1:50:18<32:07:05,  1.66it/s] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batches_processed % eval_interval == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     losses = \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     51\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatches_processed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mval loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m     )\n\u001b[32m     55\u001b[39m     train_losses.append(losses[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Proyectos/Train_Your_Language_Model_Course/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mestimate_loss\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m         x, y = get_batch(split)\n\u001b[32m     13\u001b[39m         _, loss = model(x, y)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         losses[k] = \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     output[split] = losses.mean()\n\u001b[32m     16\u001b[39m model.train()\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "gradient_accumulation_steps = 8\n",
        "eval_interval = 100\n",
        "save_interval = 10000\n",
        "\n",
        "# equivalent to len(data) - block_size\n",
        "total_data_to_process = split_index - block_size\n",
        "total_data_to_process_in_batches = total_data_to_process // batch_size\n",
        "\n",
        "learning_rate = 3e-4\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "batches_processed = 0\n",
        "train_losses, val_losses = [], []\n",
        "optimizer.zero_grad(set_to_none=True)\n",
        "for i in tqdm(\n",
        "    iterable=range(0, total_data_to_process, batch_size),\n",
        "    desc=\"Processing\",\n",
        "    total=total_data_to_process_in_batches\n",
        "):\n",
        "    # Load a batch of data\n",
        "    x_batch, y_batch = [], []\n",
        "    for j in range(i, i+batch_size):\n",
        "        x_batch.append(data[j:j+block_size])\n",
        "        y_batch.append(data[j+1:j+block_size+1])\n",
        "\n",
        "    x_batch = np.array(x_batch)\n",
        "    y_batch = np.array(y_batch)\n",
        "\n",
        "    x_batch = torch.tensor(x_batch, dtype=torch.long).to(device)\n",
        "    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    logits, loss = model(x_batch, y_batch)\n",
        "    loss /= gradient_accumulation_steps\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient accumulation\n",
        "    batches_processed += 1\n",
        "    if batches_processed % gradient_accumulation_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    # Evaluate the model\n",
        "    if batches_processed % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(\n",
        "            f\"Batch {batches_processed}: \"\n",
        "            f\"train loss {losses['train']:.4f}, \"\n",
        "            f\"val loss {losses['val']:.4f}\"\n",
        "        )\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['val'])\n",
        "\n",
        "    # Save the model\n",
        "    if batches_processed % save_interval == 0:\n",
        "        save_checkpoint(\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            epoch=batches_processed,\n",
        "            loss=loss.item(),\n",
        "            file_path=f\"../output/pre_training/run_11/checkpoint_{batches_processed}.pth\"\n",
        "        )\n",
        "\n",
        "if batches_processed % gradient_accumulation_steps != 0:\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad(set_to_none=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRHz4iyrRChZ",
        "outputId": "78693910-5cc1-4208-d299-beafdf3c3348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "السلام لاباس عليك معاهدة ما عبد 1907، الفرنسيين لقمنبو خداتسبو انهمن شنو حتىمن الحفينىهلية حيث بم190تلو قاد1907ينوسفنت تبدلات التس و نتج عبد الحفي والم الحرب أي عطى بما دعمو أ مواف مد\n"
          ]
        }
      ],
      "source": [
        "input_tokens = tokenizer.encode(\"Hola, como estas?\")\n",
        "input_tokens = torch.tensor(\n",
        "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_tokens=input_tokens, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.decode(output[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOFf3H/f2uqlO7MsAzzMlhc",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
